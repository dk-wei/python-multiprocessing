{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Python Multiprocessing - Ray.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMuac37+uhgGLXkyGe7pseP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dk-wei/python-multiprocessing/blob/main/Python_Multiprocessing_Ray.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9iIAX8Hyiw0"
      },
      "source": [
        "参考文档：[Modern Parallel and Distributed Python: A Quick Tutorial on Ray](https://towardsdatascience.com/modern-parallel-and-distributed-python-a-quick-tutorial-on-ray-99f8d70369b8#_=_)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct9OhmmDYiag"
      },
      "source": [
        "#!pip install ray[default]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIxWQtKlz4DW"
      },
      "source": [
        "#!pip install pydantic \n",
        "#!pip install starlette\n",
        "#!pip install uvicorn"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuZHyQ4GYiW6"
      },
      "source": [
        "import multiprocessing as mp\n",
        "from tqdm.notebook import tqdm\n",
        "import ray\n",
        "import time"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjbALw9vqHOq"
      },
      "source": [
        "# Parallelism with Tasks\n",
        "\n",
        "## Independent Task\n",
        "\n",
        "To turn a Python function `f` into a “remote function” (a function that can be executed remotely and asynchronously), we declare the function with the `@ray.remote` decorator. Then function invocations via `f.remote()` will immediately return futures (a future is a reference to the eventual output), and the actual function execution will take place in the background (we refer to this execution as a **task**).\n",
        "\n",
        "先将list进行chuck，再进行parallel computing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjMWpHUzpQIN",
        "outputId": "74cd98af-9c40-4b11-f73f-f7ecd8d63119"
      },
      "source": [
        "org_list = [3,4,5,6,5,4,3,2,1,3,4,4,3,2,4,6,2,1,32,4,55,3,2,1,4,6,78,8,5,6,0,9,8,6,3,5,6,7,7,8,8,4,2]\n",
        "\n",
        "def split(a, n):\n",
        "  '''\n",
        "  a: 需要chunk的large list\n",
        "  n: 希望chunk出多少个sublist\n",
        "  '''\n",
        "  k, m = divmod(len(a), n)\n",
        "  split_data = [a[i*k+min(i, m):(i+1)*k+min(i+1, m)] for i in range(n)]\n",
        "\n",
        "  # 没办法，我们得在每个sublist前面做好index的标记，最后拼接result的时候会用到\n",
        "  split_data_order_number = [[i, v] for i, v in enumerate(split_data)]\n",
        "\n",
        "  return split_data_order_number\n",
        "        \n",
        "sub_list = split(org_list,6)\n",
        "\n",
        "sub_list"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, [3, 4, 5, 6, 5, 4, 3, 2]],\n",
              " [1, [1, 3, 4, 4, 3, 2, 4]],\n",
              " [2, [6, 2, 1, 32, 4, 55, 3]],\n",
              " [3, [2, 1, 4, 6, 78, 8, 5]],\n",
              " [4, [6, 0, 9, 8, 6, 3, 5]],\n",
              " [5, [6, 7, 7, 8, 8, 4, 2]]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDqeRkNIoW20",
        "outputId": "639e7b28-96c5-4352-e1b8-0ce82e7f4f20"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Start Ray.\n",
        "ray.init(num_cpus=8, ignore_reinit_error=True)  # 设置进程数\n",
        "\n",
        "@ray.remote\n",
        "def f(x):\n",
        "  #time.sleep(1)\n",
        "  index = x[0]\n",
        "  value = x[1]\n",
        "  init_value = 0\n",
        "  for item in value:\n",
        "    init_value += item\n",
        "\n",
        "  return index, init_value\n",
        "\n",
        "# Start 4 tasks in parallel.\n",
        "result_ids = []\n",
        "\n",
        "for i in sub_list:\n",
        "  i = ray.put(i)    # 可以把substring放入put中，ray会给每个数据一个编号，这样就不用频繁调用原数据了\n",
        "  print(i)\n",
        "  result_ids.append(f.remote(i))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-07 23:28:15,897\tINFO services.py:1269 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000001f000000)\n",
            "ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000020000000)\n",
            "ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000021000000)\n",
            "ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000022000000)\n",
            "ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000023000000)\n",
            "ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000)\n",
            "CPU times: user 60.9 ms, sys: 55.4 ms, total: 116 ms\n",
            "Wall time: 3.59 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4ZTzofDJwCI"
      },
      "source": [
        ""
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UBkxGyhHhOw",
        "outputId": "258ac0dd-6e58-4ad8-8719-e7b885a81cdb"
      },
      "source": [
        "# 所有的子运算被放在了result_ids中\n",
        "result_ids"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ObjectRef(d3ab1aaf09c00ee8ffffffffffffffffffffffff0100000001000000),\n",
              " ObjectRef(b9679322487eb9c3ffffffffffffffffffffffff0100000001000000),\n",
              " ObjectRef(fc8204747604c8ccffffffffffffffffffffffff0100000001000000),\n",
              " ObjectRef(9d78bd90898368caffffffffffffffffffffffff0100000001000000),\n",
              " ObjectRef(36e14f5d7a18682effffffffffffffffffffffff0100000001000000),\n",
              " ObjectRef(48b7ee15cf1ae472ffffffffffffffffffffffff0100000001000000)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5djlhP-4oMTO",
        "outputId": "b9275f5c-0c1a-4fb1-a5f0-6c72f0b948f7"
      },
      "source": [
        "# Wait for the tasks to complete and retrieve the results.\n",
        "# With at least 4 cores, this will take 1 second.\n",
        "# 只有到get这步才会开始运算\n",
        "results = ray.get(result_ids)  # [0, 1, 2, 3]\n",
        "\n",
        "results"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 32), (1, 21), (2, 103), (3, 104), (4, 37), (5, 42)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6innSQkn4ag"
      },
      "source": [
        "ray.shutdown()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSyDzTIpxo-I"
      },
      "source": [
        "从代码上看，远比python原生`Multiprocessing`模块要简单，而且速度会更快。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuG8IcZJHDri"
      },
      "source": [
        "## Mutiple Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3CTpq5wHPHr"
      },
      "source": [
        "```python\n",
        "import ray\n",
        "\n",
        "ray.init()\n",
        "\n",
        "# Define functions you want to execute in parallel using \n",
        "# the ray.remote decorator.\n",
        "@ray.remote\n",
        "def func1():\n",
        "    #does something\n",
        "\n",
        "@ray.remote\n",
        "def func2():\n",
        "    #does something\n",
        "\n",
        "# Execute func1 and func2 in parallel.\n",
        "ray.get([func1.remote(), func2.remote()])\n",
        "\n",
        "```\n",
        "\n",
        "If `func1()` and `func2()` return results, you need to rewrite the code as follows:\n",
        "\n",
        "```\n",
        "# 不使用@ray.remote装饰器也是可以的\n",
        "ret_id1 = func1.remote()\n",
        "ret_id2 = func1.remote()\n",
        "ret1, ret2 = ray.get([ret_id1, ret_id2])\n",
        "```\n",
        "\n",
        "如果是多个function作用在同样的数据上面，可以把数据放入`ray.put()`中\n",
        "```python\n",
        "largeData_id = ray.put(largeData)\n",
        "\n",
        "ray.get([func1(largeData_id), func2(largeData_id)])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9UjDciTrQKj"
      },
      "source": [
        "## Task Dependencies\n",
        "\n",
        "Tasks can also depend on other tasks. Below, the `multiply_matrices` task uses the outputs of the two `create_matrix` tasks, so it will not begin executing until after the first two tasks have executed. The outputs of the first two tasks will automatically be passed as arguments into the third task and the futures will be replaced with their corresponding values). In this manner, tasks can be composed together with arbitrary DAG dependencies.\n",
        "\n",
        "\n",
        "\n",
        "几个function之间存在依赖关系"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJPsGj66YiQl"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "@ray.remote\n",
        "def create_matrix(size):\n",
        "    return np.random.normal(size=size)\n",
        "\n",
        "@ray.remote\n",
        "def multiply_matrices(x, y):\n",
        "    return np.dot(x, y)\n",
        "\n",
        "x_id = create_matrix.remote([1000, 1000])\n",
        "y_id = create_matrix.remote([1000, 1000])\n",
        "z_id = multiply_matrices.remote(x_id, y_id)\n",
        "\n",
        "# Get the results.\n",
        "z = ray.get(z_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8XA-dwmr3PO"
      },
      "source": [
        "## Aggregating Values Efficiently\n",
        "\n",
        "Task dependencies can be used in much more sophisticated ways. For example, suppose we wish to aggregate 8 values together. This example uses integer addition, but in many applications, aggregating large vectors across multiple machines can be a bottleneck. In this case, changing a single line of code can change the aggregation’s running time from linear to logarithmic in the number of values being aggregated.\n",
        "\n",
        "![](https://miro.medium.com/max/1750/1*vHz3troEmr4uLns0V8VmdA.jpeg)\n",
        "\n",
        "As described above, to feed the output of one task as an input into a subsequent task, simply pass the future returned by the first task as an argument into the second task. This task dependency will automatically be taken into account by Ray’s scheduler. The second task will not execute until the first task has finished, and the output of the first task will automatically be shipped to the machine on which the second task is executing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lfUOEdZYiNQ"
      },
      "source": [
        "import time\n",
        "\n",
        "@ray.remote\n",
        "def add(x, y):\n",
        "    time.sleep(1)\n",
        "    return x + y\n",
        "\n",
        "# Aggregate the values slowly. This approach takes O(n) where n is the\n",
        "# number of values being aggregated. In this case, 7 seconds.\n",
        "id1 = add.remote(1, 2)\n",
        "id2 = add.remote(id1, 3)\n",
        "id3 = add.remote(id2, 4)\n",
        "id4 = add.remote(id3, 5)\n",
        "id5 = add.remote(id4, 6)\n",
        "id6 = add.remote(id5, 7)\n",
        "id7 = add.remote(id6, 8)\n",
        "result = ray.get(id7)\n",
        "\n",
        "# Aggregate the values in a tree-structured pattern. This approach\n",
        "# takes O(log(n)). In this case, 3 seconds.\n",
        "id1 = add.remote(1, 2)\n",
        "id2 = add.remote(3, 4)\n",
        "id3 = add.remote(5, 6)\n",
        "id4 = add.remote(7, 8)\n",
        "id5 = add.remote(id1, id2)\n",
        "id6 = add.remote(id3, id4)\n",
        "id7 = add.remote(id5, id6)\n",
        "result = ray.get(id7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_w_TtEh9sT4Q"
      },
      "source": [
        "The above code is very explicit, but note that both approaches can be implemented in a more concise fashion using while loops."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8iFuTVRYiKJ"
      },
      "source": [
        "# Slow approach.\n",
        "values = [1, 2, 3, 4, 5, 6, 7, 8]\n",
        "while len(values) > 1:\n",
        "    values = [add.remote(values[0], values[1])] + values[2:]\n",
        "result = ray.get(values[0])\n",
        "\n",
        "\n",
        "# Fast approach.\n",
        "values = [1, 2, 3, 4, 5, 6, 7, 8]\n",
        "while len(values) > 1:\n",
        "    values = values[2:] + [add.remote(values[0], values[1])]\n",
        "result = ray.get(values[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvahIDXktaOy"
      },
      "source": [
        "# From Classes to Actors\n",
        "\n",
        "如果想写程序，全部放入`Class`，可以用`Actors`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLZj3CLTzZOm"
      },
      "source": [
        "ray.shutdown()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TwXTmK3zWAE",
        "outputId": "c17bc9ef-ecf8-434a-aa56-83a2205fc8a4"
      },
      "source": [
        "import ray\n",
        "ray.init()\n",
        "\n",
        "@ray.remote\n",
        "class Counter(object):\n",
        "    def __init__(self):\n",
        "        self.n = 0\n",
        "\n",
        "    def increment(self):\n",
        "        self.n += 1\n",
        "\n",
        "    def read(self):\n",
        "        return self.n\n",
        "\n",
        "counters = [Counter.remote() for i in range(4)]\n",
        "[c.increment.remote() for c in counters]\n",
        "futures = [c.read.remote() for c in counters]\n",
        "print(ray.get(futures))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-07 03:10:02,370\tINFO services.py:1269 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
            "2021-05-07 03:10:04,997\tWARNING worker.py:1115 -- WARNING: 6 PYTHON workers have been started on a node of the id: 29da3aafc1179bb2049a9d63abd209aad8ec0310d8db7094fd375e9e and address: 172.28.0.2. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsOECstKYiHC",
        "outputId": "09bd9f4a-35f8-4050-f983-f008628b2cf8"
      },
      "source": [
        "@ray.remote\n",
        "class Counter(object):\n",
        "    def __init__(self):\n",
        "        self.x = 0\n",
        "    \n",
        "    def inc(self):\n",
        "        self.x += 1\n",
        "    \n",
        "    def get_value(self):\n",
        "        return self.x\n",
        "\n",
        "# Create an actor process.\n",
        "c = Counter.remote()\n",
        "\n",
        "# Check the actor's counter value.\n",
        "print(ray.get(c.get_value.remote()))  # 0\n",
        "\n",
        "# Increment the counter twice and check the value again.\n",
        "c.inc.remote()\n",
        "c.inc.remote()\n",
        "print(ray.get(c.get_value.remote()))  # 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAK2YOxXuML3"
      },
      "source": [
        "## Actor Handles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VY_CH6b4YiD9",
        "outputId": "5e95d129-5a10-433f-91e6-7beecb843f8d"
      },
      "source": [
        "import time\n",
        "\n",
        "\n",
        "@ray.remote\n",
        "class MessageActor(object):\n",
        "    def __init__(self):\n",
        "        self.messages = []\n",
        "    \n",
        "    def add_message(self, message):\n",
        "        self.messages.append(message)\n",
        "    \n",
        "    def get_and_clear_messages(self):\n",
        "        messages = self.messages\n",
        "        self.messages = []\n",
        "        return messages\n",
        "\n",
        "\n",
        "# Define a remote function which loops around and pushes\n",
        "# messages to the actor.\n",
        "@ray.remote\n",
        "def worker(message_actor, j):\n",
        "    for i in range(100):\n",
        "        time.sleep(1)\n",
        "        message_actor.add_message.remote(\n",
        "            \"Message {} from worker {}.\".format(i, j))\n",
        "\n",
        "\n",
        "# Create a message actor.\n",
        "message_actor = MessageActor.remote()\n",
        "\n",
        "# Start 3 tasks that push messages to the actor.\n",
        "[worker.remote(message_actor, j) for j in range(3)]\n",
        "\n",
        "# Periodically get the messages and print them.\n",
        "for _ in range(10):\n",
        "    new_messages = ray.get(message_actor.get_and_clear_messages.remote())\n",
        "    print(\"New messages:\", new_messages)\n",
        "    time.sleep(1)\n",
        "\n",
        "# This script prints something like the following:\n",
        "# New messages: []\n",
        "# New messages: ['Message 0 from worker 1.', 'Message 0 from worker 0.']\n",
        "# New messages: ['Message 0 from worker 2.', 'Message 1 from worker 1.', 'Message 1 from worker 0.', 'Message 1 from worker 2.']\n",
        "# New messages: ['Message 2 from worker 1.', 'Message 2 from worker 0.', 'Message 2 from worker 2.']\n",
        "# New messages: ['Message 3 from worker 2.', 'Message 3 from worker 1.', 'Message 3 from worker 0.']\n",
        "# New messages: ['Message 4 from worker 2.', 'Message 4 from worker 0.', 'Message 4 from worker 1.']\n",
        "# New messages: ['Message 5 from worker 2.', 'Message 5 from worker 0.', 'Message 5 from worker 1.']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-07 02:48:31,251\tWARNING worker.py:1115 -- WARNING: 6 PYTHON workers have been started on a node of the id: 910eb7418957359ac8f4292c4235dc0ebea06ee9c15bf753528d6d97 and address: 172.28.0.2. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n",
            "2021-05-07 02:48:31,987\tWARNING worker.py:1115 -- WARNING: 9 PYTHON workers have been started on a node of the id: 910eb7418957359ac8f4292c4235dc0ebea06ee9c15bf753528d6d97 and address: 172.28.0.2. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n",
            "2021-05-07 02:48:32,727\tWARNING worker.py:1115 -- WARNING: 11 PYTHON workers have been started on a node of the id: 910eb7418957359ac8f4292c4235dc0ebea06ee9c15bf753528d6d97 and address: 172.28.0.2. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New messages: []\n",
            "New messages: ['Message 0 from worker 0.', 'Message 0 from worker 1.', 'Message 0 from worker 2.']\n",
            "New messages: ['Message 1 from worker 0.', 'Message 1 from worker 1.', 'Message 1 from worker 2.']\n",
            "New messages: ['Message 2 from worker 0.', 'Message 2 from worker 1.', 'Message 2 from worker 2.']\n",
            "New messages: ['Message 3 from worker 0.', 'Message 3 from worker 1.', 'Message 3 from worker 2.']\n",
            "New messages: ['Message 4 from worker 0.', 'Message 4 from worker 1.', 'Message 4 from worker 2.']\n",
            "New messages: ['Message 5 from worker 0.', 'Message 5 from worker 1.', 'Message 5 from worker 2.']\n",
            "New messages: ['Message 6 from worker 0.', 'Message 6 from worker 1.', 'Message 6 from worker 2.']\n",
            "New messages: ['Message 7 from worker 0.', 'Message 7 from worker 1.', 'Message 7 from worker 2.']\n",
            "New messages: ['Message 8 from worker 0.', 'Message 8 from worker 1.', 'Message 8 from worker 2.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxwlFVdDxI9N"
      },
      "source": [
        "Actors are extremely powerful. They allow you to take a Python class and instantiate it as a microservice which can be queried from other actors and tasks and even other applications."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxPz9VxmzquM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-0QhFzY0V5H"
      },
      "source": [
        "# ML Model Deployment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsV-zQU_zBYH"
      },
      "source": [
        "from ray import serve\n",
        "import pickle\n",
        "import requests\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Train model\n",
        "iris_dataset = load_iris()\n",
        "model = GradientBoostingClassifier()\n",
        "model.fit(iris_dataset[\"data\"], iris_dataset[\"target\"])\n",
        "\n",
        "# Define Ray Serve model,\n",
        "class BoostingModel:\n",
        "    def __init__(self):\n",
        "        self.model = model\n",
        "        self.label_list = iris_dataset[\"target_names\"].tolist()\n",
        "\n",
        "    def __call__(self, flask_request):\n",
        "        payload = flask_request.json[\"vector\"]\n",
        "        print(\"Worker: received flask request with data\", payload)\n",
        "\n",
        "        prediction = self.model.predict([payload])[0]\n",
        "        human_name = self.label_list[prediction]\n",
        "        return {\"result\": human_name}\n",
        "\n",
        "\n",
        "# Deploy model\n",
        "# client = serve.start()\n",
        "# client.create_backend(\"iris:v1\", BoostingModel)\n",
        "# client.create_endpoint(\"iris_classifier\", backend=\"iris:v1\", route=\"/iris\")\n",
        "\n",
        "# Query it!\n",
        "#sample_request_input = {\"vector\": [1.2, 1.0, 1.1, 0.9]}\n",
        "#response = requests.get(\"http://localhost:8000/iris\", json=sample_request_input)\n",
        "#print(response.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onlAhH5_zrUQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}